{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud prediction with the Multi-Subset Observation Undersampling (OU) \n",
    "## Model by Perols et al. (2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The phenomenon of fraud is rare but expensive (to the industry and its customers). However it is a fascinating aspect of human behavior, and it's a worthy subject of study. Why? The problems that englobe its understanding are far from trivial.\n",
    "\n",
    "Fraud, to be possible, needs three elements:\n",
    "- A supply of motivated fraudsters.\n",
    "- Availability of suitable targets.\n",
    "- The absence of vigilantes.\n",
    "\n",
    "Motivated offenders and visible targets will always be available. And we (the scientists, engineers, thinkers, etc.), could be seen as one of the layers of 'vigilantes,' adept enough to prevent the attacks of these sophisticated thieves.\n",
    "\n",
    "One of the main challenges is that fraudsters adapt to our defenses, and we (the vigilantes) have to engineer new barriers, playing always an arms race with the fraudsters. This phenomenon is known as the Red Queen Effect by evolutionary biologists and could be seen by some people as a headache that burns resources. I myself, think of it as a drive to innovation.\n",
    "\n",
    "One of the solutions to overcome this problem is to detect fraud instances in real-time, or even forecast them. This can be done by constructing predictive models with math as our building blocks, computer operations as our cement, and science and literature as our blue prints. Because of the Red Queen Effect, these models will need a constant re-think.\n",
    "\n",
    "Hence, here is my attempt to demonstrate how this can be done.\n",
    "\n",
    "\n",
    "José P. Barrantes, <br>\n",
    "Data Scientist\n",
    "\n",
    "17/Dec/2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About this project and methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strength of this methodology is in the data preprocessing phase, it is designed to address the class unbalance problem. This pre-processing architecture consists in generating several training subsets, each one will contain a copy of all the instances of the minority class (the frauds in this case) available in the training set, and several random instances of the majority class.\n",
    "<br> <br>\n",
    "Each of these subsets is used to train a classifier, hoping that it will learn better to recognise the minority class. Later, groups of classifiers are combined in a global (ensembled) classifier who can discern better between classes. An analogy can be used to explain this: each individual model is a voter, and it chooses to which class belongs the instance we are testing, in the end, we count the votes to take our decision.\n",
    "<br> <br>\n",
    "Here we will use a 'soft-voting' system, as part of our process of decision making. This means that we run our models with an example transaction, we get the probability (of the example belonging to the fraud class) of each model, and we average them. If the value excedes a fixed threshold, we classify the instance as a positive case. This threshold is determined by an algorithm that minimizes our performance metric, the Expected Cost of Misclassification.\n",
    "<br> <br>\n",
    "So, we should have an ensemble algorithm who is able to recognize fraud cases and differenciate them from true transactions. You can find more details about the model design and methodology in the file README.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit  # To do stratified sampling.\n",
    "import model_metrics_parallel as mmp # Custom library to manage some metrics needed for fine-tuning and optimization.\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from ensemble_model import Ensemble_model # Also, a custom library made to manage the construction of ensembles with the required specs.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # To plot the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables:\n",
    "- V1 - V28: results of a dimensionality reduction from PCA.\n",
    "- Amount:   transaction amount.\n",
    "- Time:     relative time of the transaction event. \n",
    "- Class:    0 true transaction. 1 fraudulent transaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find this data set with all the details in Kaggle:\n",
    "https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('source_data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get rid of the Time variable cause its scale could affect the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.drop('Time', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'Amount' column covers a huge range. Convert to log-space.\n",
    "eps=0.001 # to avoid errors due the log operation\n",
    "raw_data['Log Ammount'] = np.log(raw_data.Amount + eps)\n",
    "\n",
    "# Eliminate the original 'Amount'\n",
    "raw_data.drop('Amount', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our test set to be representative of the two-class categories. Hence we do a stratified partition of the sets. \n",
    "The test set is only to check (at the end) if our model can generalize to new data. We will train our models with the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified sapling based on the fraud category\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(raw_data, raw_data['Class']):\n",
    "    strat_train_set = raw_data.loc[train_index]\n",
    "    strat_test_set  = raw_data.loc[test_index]\n",
    "    \n",
    "# we wont use the test_set until the final phase. Just remember it is there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227845"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(strat_train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we will need a validation set to fine-tune our model hyperparameters, and to evaluate other metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set_1 = strat_train_set.reset_index() # without this, the method would sample empty indexes.\n",
    "\n",
    "for train_index, val_index in split.split(strat_train_set_1, strat_train_set_1['Class']):\n",
    "    val_set    = strat_train_set_1.loc[val_index]\n",
    "    train_set  = strat_train_set_1.loc[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of the new index col\n",
    "val_set.drop('index', axis=1, inplace=True)\n",
    "train_set.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the class proportions in the sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998271\n",
       "1    0.001729\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set['Class'].value_counts() / len(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.99828\n",
       "1    0.00172\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_test_set['Class'].value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998272\n",
       "1    0.001728\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['Class'].value_counts() / len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998266\n",
       "1    0.001734\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set['Class'].value_counts() / len(val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, just around 0.2% of our instances are frauds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build of Observation Undersampling architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Perols _et al._ (2017), we will need all the fraudulent instances for each of our OU subsets. So, we separate 2 subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "frauds        = train_set.loc[train_set['Class'] == 1]\n",
    "true_transac  = train_set.loc[train_set['Class'] == 0]\n",
    "\n",
    "# the shuffled sample could produce duplicates, so we will drop them\n",
    "frauds        = frauds.drop_duplicates()\n",
    "true_transac  = true_transac.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so, we are left with these fraud cases for our training\n",
    "len(frauds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "575.8227848101266"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_set.loc[val_set['Class'] == 0]) / len(val_set.loc[val_set['Class'] == 1])\n",
    "# Of 577 transaction, one is a fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of Observation Undersampling (OU) subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to generate our subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ou_subsets(subset_amount=12, as_np=False):\n",
    "    \"\"\"\n",
    "    This function generates our training Observation undersampling subsets.\n",
    "    Each subset cotains all the training fraud instances, and the total size of the subset is choosen so we have a 20% fraud instances.\n",
    "    \n",
    "    Returns:\n",
    "        A list with the amount of training subsets required by the user. Perols et al. (2017) recommends 12.\n",
    "    \"\"\"\n",
    "    \n",
    "    true_transc_amount = 1500 - len(frauds) # this leave around 20% of fraud cases in each subset\n",
    "    ou_subsets         = []                 # a list of dataframes. Each df is the shuffled true transactions, plus the all the frauds available.\n",
    "    slice_index_i      = 0                  # the start of our df chunk\n",
    "    slice_index_f      = true_transc_amount # the end of our df chunk\n",
    "    \n",
    "    ## Next is what the function does if we want np arrays\n",
    "    if as_np == True:\n",
    "        labels_subset      = []     # a list with the labels, if we opt for the np structures\n",
    "        bool_labels        = []\n",
    "    \n",
    "        i = 0\n",
    "        while i < subset_amount:\n",
    "            ou_subsets.append( np.array(pd.concat([true_transac[slice_index_i:slice_index_f], frauds]).drop(['Class'], axis=1)) ) # the pandas df is inputed to the list as a np.array. Also the variables Class and index are excluded.\n",
    "            labels_subset.append( np.array(pd.concat([true_transac[slice_index_i:slice_index_f], frauds]).Class) ) # the pandas df is inputed to the list as a np.array. Also the variables Class and index are excluded.\n",
    "            bool_labels.append( np.array(pd.concat([true_transac[slice_index_i:slice_index_f], frauds]).Class) != 0 )\n",
    "            \n",
    "            i += 1\n",
    "            slice_index_i += true_transc_amount\n",
    "            slice_index_f += true_transc_amount\n",
    "            \n",
    "        return ou_subsets, labels_subset, bool_labels\n",
    "        \n",
    "    # And if we want the result as pandas df:\n",
    "    i = 0\n",
    "    while i < subset_amount:\n",
    "        ou_subsets.append( pd.concat([true_transac[slice_index_i:slice_index_f], frauds]) )\n",
    "        \n",
    "        i += 1\n",
    "        slice_index_i += true_transc_amount\n",
    "        slice_index_f += true_transc_amount\n",
    "                \n",
    "    return ou_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can do this, to gernerate subsets for a 10-fold cross validation. 120 in total.\n",
    "training_subsets_10_fold = generate_ou_subsets(subset_amount=12*10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use our ou subsets to train some models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVMs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With each subset, we train a support vector machine (SVM). This trained models are stored in the list 'svm_models.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0 appended.\n",
      "Model 1 appended.\n",
      "Model 2 appended.\n",
      "Model 3 appended.\n",
      "Model 4 appended.\n",
      "Model 5 appended.\n",
      "Model 6 appended.\n",
      "Model 7 appended.\n",
      "Model 8 appended.\n",
      "Model 9 appended.\n",
      "Model 10 appended.\n",
      "Model 11 appended.\n",
      "Model 12 appended.\n",
      "Model 13 appended.\n",
      "Model 14 appended.\n",
      "Model 15 appended.\n",
      "Model 16 appended.\n",
      "Model 17 appended.\n",
      "Model 18 appended.\n",
      "Model 19 appended.\n",
      "Model 20 appended.\n",
      "Model 21 appended.\n",
      "Model 22 appended.\n",
      "Model 23 appended.\n",
      "Model 24 appended.\n",
      "Model 25 appended.\n",
      "Model 26 appended.\n",
      "Model 27 appended.\n",
      "Model 28 appended.\n",
      "Model 29 appended.\n",
      "Model 30 appended.\n",
      "Model 31 appended.\n",
      "Model 32 appended.\n",
      "Model 33 appended.\n",
      "Model 34 appended.\n",
      "Model 35 appended.\n",
      "Model 36 appended.\n",
      "Model 37 appended.\n",
      "Model 38 appended.\n",
      "Model 39 appended.\n",
      "Model 40 appended.\n",
      "Model 41 appended.\n",
      "Model 42 appended.\n",
      "Model 43 appended.\n",
      "Model 44 appended.\n",
      "Model 45 appended.\n",
      "Model 46 appended.\n",
      "Model 47 appended.\n",
      "Model 48 appended.\n",
      "Model 49 appended.\n",
      "Model 50 appended.\n",
      "Model 51 appended.\n",
      "Model 52 appended.\n",
      "Model 53 appended.\n",
      "Model 54 appended.\n",
      "Model 55 appended.\n",
      "Model 56 appended.\n",
      "Model 57 appended.\n",
      "Model 58 appended.\n",
      "Model 59 appended.\n",
      "Model 60 appended.\n",
      "Model 61 appended.\n",
      "Model 62 appended.\n",
      "Model 63 appended.\n",
      "Model 64 appended.\n",
      "Model 65 appended.\n",
      "Model 66 appended.\n",
      "Model 67 appended.\n",
      "Model 68 appended.\n",
      "Model 69 appended.\n",
      "Model 70 appended.\n",
      "Model 71 appended.\n",
      "Model 72 appended.\n",
      "Model 73 appended.\n",
      "Model 74 appended.\n",
      "Model 75 appended.\n",
      "Model 76 appended.\n",
      "Model 77 appended.\n",
      "Model 78 appended.\n",
      "Model 79 appended.\n",
      "Model 80 appended.\n",
      "Model 81 appended.\n",
      "Model 82 appended.\n",
      "Model 83 appended.\n",
      "Model 84 appended.\n",
      "Model 85 appended.\n",
      "Model 86 appended.\n",
      "Model 87 appended.\n",
      "Model 88 appended.\n",
      "Model 89 appended.\n",
      "Model 90 appended.\n",
      "Model 91 appended.\n",
      "Model 92 appended.\n",
      "Model 93 appended.\n",
      "Model 94 appended.\n",
      "Model 95 appended.\n",
      "Model 96 appended.\n",
      "Model 97 appended.\n",
      "Model 98 appended.\n",
      "Model 99 appended.\n",
      "Model 100 appended.\n",
      "Model 101 appended.\n",
      "Model 102 appended.\n",
      "Model 103 appended.\n",
      "Model 104 appended.\n",
      "Model 105 appended.\n",
      "Model 106 appended.\n",
      "Model 107 appended.\n",
      "Model 108 appended.\n",
      "Model 109 appended.\n",
      "Model 110 appended.\n",
      "Model 111 appended.\n",
      "Model 112 appended.\n",
      "Model 113 appended.\n",
      "Model 114 appended.\n",
      "Model 115 appended.\n",
      "Model 116 appended.\n",
      "Model 117 appended.\n",
      "Model 118 appended.\n",
      "Model 119 appended.\n"
     ]
    }
   ],
   "source": [
    "svm_models = []                         # List to store our models\n",
    "n_mod = 0\n",
    "for subset in training_subsets_10_fold:\n",
    "    X = subset.drop(['Class'], axis=1)  # Features\n",
    "    y = subset.Class                    # Labels\n",
    "    svm_models.append(SVC(kernel='rbf', probability=True, gamma='auto').fit(X, y)) # the gamma parameter must be double cheched\n",
    "    print('Model ' + str(n_mod) + ' appended.')  # This just to know the progress\n",
    "    n_mod += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, we also fit logistic regressions with the subsets. Later we will do ensembles with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0 appended.\n",
      "Model 1 appended.\n",
      "Model 2 appended.\n",
      "Model 3 appended.\n",
      "Model 4 appended.\n",
      "Model 5 appended.\n",
      "Model 6 appended.\n",
      "Model 7 appended.\n",
      "Model 8 appended.\n",
      "Model 9 appended.\n",
      "Model 10 appended.\n",
      "Model 11 appended.\n",
      "Model 12 appended.\n",
      "Model 13 appended.\n",
      "Model 14 appended.\n",
      "Model 15 appended.\n",
      "Model 16 appended.\n",
      "Model 17 appended.\n",
      "Model 18 appended.\n",
      "Model 19 appended.\n",
      "Model 20 appended.\n",
      "Model 21 appended.\n",
      "Model 22 appended.\n",
      "Model 23 appended.\n",
      "Model 24 appended.\n",
      "Model 25 appended.\n",
      "Model 26 appended.\n",
      "Model 27 appended.\n",
      "Model 28 appended.\n",
      "Model 29 appended.\n",
      "Model 30 appended.\n",
      "Model 31 appended.\n",
      "Model 32 appended.\n",
      "Model 33 appended.\n",
      "Model 34 appended.\n",
      "Model 35 appended.\n",
      "Model 36 appended.\n",
      "Model 37 appended.\n",
      "Model 38 appended.\n",
      "Model 39 appended.\n",
      "Model 40 appended.\n",
      "Model 41 appended.\n",
      "Model 42 appended.\n",
      "Model 43 appended.\n",
      "Model 44 appended.\n",
      "Model 45 appended.\n",
      "Model 46 appended.\n",
      "Model 47 appended.\n",
      "Model 48 appended.\n",
      "Model 49 appended.\n",
      "Model 50 appended.\n",
      "Model 51 appended.\n",
      "Model 52 appended.\n",
      "Model 53 appended.\n",
      "Model 54 appended.\n",
      "Model 55 appended.\n",
      "Model 56 appended.\n",
      "Model 57 appended.\n",
      "Model 58 appended.\n",
      "Model 59 appended.\n",
      "Model 60 appended.\n",
      "Model 61 appended.\n",
      "Model 62 appended.\n",
      "Model 63 appended.\n",
      "Model 64 appended.\n",
      "Model 65 appended.\n",
      "Model 66 appended.\n",
      "Model 67 appended.\n",
      "Model 68 appended.\n",
      "Model 69 appended.\n",
      "Model 70 appended.\n",
      "Model 71 appended.\n",
      "Model 72 appended.\n",
      "Model 73 appended.\n",
      "Model 74 appended.\n",
      "Model 75 appended.\n",
      "Model 76 appended.\n",
      "Model 77 appended.\n",
      "Model 78 appended.\n",
      "Model 79 appended.\n",
      "Model 80 appended.\n",
      "Model 81 appended.\n",
      "Model 82 appended.\n",
      "Model 83 appended.\n",
      "Model 84 appended.\n",
      "Model 85 appended.\n",
      "Model 86 appended.\n",
      "Model 87 appended.\n",
      "Model 88 appended.\n",
      "Model 89 appended.\n",
      "Model 90 appended.\n",
      "Model 91 appended.\n",
      "Model 92 appended.\n",
      "Model 93 appended.\n",
      "Model 94 appended.\n",
      "Model 95 appended.\n",
      "Model 96 appended.\n",
      "Model 97 appended.\n",
      "Model 98 appended.\n",
      "Model 99 appended.\n",
      "Model 100 appended.\n",
      "Model 101 appended.\n",
      "Model 102 appended.\n",
      "Model 103 appended.\n",
      "Model 104 appended.\n",
      "Model 105 appended.\n",
      "Model 106 appended.\n",
      "Model 107 appended.\n",
      "Model 108 appended.\n",
      "Model 109 appended.\n",
      "Model 110 appended.\n",
      "Model 111 appended.\n",
      "Model 112 appended.\n",
      "Model 113 appended.\n",
      "Model 114 appended.\n",
      "Model 115 appended.\n",
      "Model 116 appended.\n",
      "Model 117 appended.\n",
      "Model 118 appended.\n",
      "Model 119 appended.\n"
     ]
    }
   ],
   "source": [
    "logistic_models = []\n",
    "n_mod = 0\n",
    "for subset in training_subsets_10_fold:\n",
    "    X = subset.drop(['Class'], axis=1)\n",
    "    y = subset.Class\n",
    "    logistic_models.append(LogisticRegression(solver='newton-cg').fit(X, y)) \n",
    "    print('Model ' + str(n_mod) + ' appended.')\n",
    "    n_mod += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling our models and finding the optimal cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us generate 10 ensembled SVM models. Each of these ensembles is composed of 12 models. <br>\n",
    "I've developed the Ensemble_model class in order to manage the ensembled models, their performance metrics, and the predictions that can be done with them. The class constructor receives a list of pre-trained models, the test set (or the set of instances we want to classify), and the cutoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cutoff (fine tuning of the model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cutoff is the threshold who defines it until what probability it's okay to recognize the instance as a fraud. The optimal cutoff is the one who renders the minimum ECM, so we want to minimize ECM. It will be determined by using the validation set, and the method \"find_min_ECM()\" that I coded.\n",
    "\n",
    "We use the validation set to avoid our models from peeping at the test data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble 0 ready.\n",
      "Ensemble 1 ready.\n",
      "Ensemble 2 ready.\n",
      "Ensemble 3 ready.\n",
      "Ensemble 4 ready.\n",
      "Ensemble 5 ready.\n",
      "Ensemble 6 ready.\n",
      "Ensemble 7 ready.\n",
      "Ensemble 8 ready.\n",
      "Ensemble 9 ready.\n"
     ]
    }
   ],
   "source": [
    "ensenmble_svms_calibration = []\n",
    "chunk_i = 0\n",
    "chunk_f =12\n",
    "for n in range(0,10):\n",
    "    ensenmble_svms_calibration.append(Ensemble_model(svm_models[chunk_i:chunk_f], val_set, 0.9))\n",
    "    chunk_i += 12\n",
    "    chunk_f += 12\n",
    "    print(\"Ensemble \" + str(n) + \" ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The min(ECM) for ensemble 0 is: 0.7000000000000001\n",
      "The min(ECM) for ensemble 1 is: 0.7000000000000001\n",
      "The min(ECM) for ensemble 2 is: 0.8\n",
      "The min(ECM) for ensemble 3 is: 0.7000000000000001\n",
      "The min(ECM) for ensemble 4 is: 0.8\n",
      "The min(ECM) for ensemble 5 is: 0.8\n",
      "The min(ECM) for ensemble 6 is: 0.7000000000000001\n",
      "The min(ECM) for ensemble 7 is: 0.8\n",
      "The min(ECM) for ensemble 8 is: 0.8\n",
      "The min(ECM) for ensemble 9 is: 0.8\n"
     ]
    }
   ],
   "source": [
    "ens_n = 0\n",
    "for ensemble in ensenmble_svms_calibration:\n",
    "    print(\"The min(ECM) for ensemble \" + str(ens_n) + \" is: \" + str(ensemble.find_min_ECM()) )\n",
    "    ens_n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the optimal cutoff for our SVMs is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8099999999999999"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svms_cutoff = 0\n",
    "for ensemble in ensenmble_svms_calibration:\n",
    "    svms_cutoff += ensemble.min_ECM / len(ensenmble_svms_calibration)\n",
    "    \n",
    "svms_cutoff + 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the logistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble 0 ready.\n",
      "Ensemble 1 ready.\n",
      "Ensemble 2 ready.\n",
      "Ensemble 3 ready.\n",
      "Ensemble 4 ready.\n",
      "Ensemble 5 ready.\n",
      "Ensemble 6 ready.\n",
      "Ensemble 7 ready.\n",
      "Ensemble 8 ready.\n",
      "Ensemble 9 ready.\n"
     ]
    }
   ],
   "source": [
    "ensenmble_logistic_models_calibration = []\n",
    "chunk_i = 0\n",
    "chunk_f =12\n",
    "for n in range(0,10):\n",
    "    ensenmble_logistic_models_calibration.append(Ensemble_model(logistic_models[chunk_i:chunk_f], val_set, 0.9))\n",
    "    chunk_i += 12\n",
    "    chunk_f += 12\n",
    "    print(\"Ensemble \" + str(n) + \" ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The min(ECM) for ensemble 0 is: 0.6000000000000001\n",
      "The min(ECM) for ensemble 1 is: 0.6000000000000001\n",
      "The min(ECM) for ensemble 2 is: 0.8\n",
      "The min(ECM) for ensemble 3 is: 0.6000000000000001\n",
      "The min(ECM) for ensemble 4 is: 0.6000000000000001\n",
      "The min(ECM) for ensemble 5 is: 0.8\n",
      "The min(ECM) for ensemble 6 is: 0.6000000000000001\n",
      "The min(ECM) for ensemble 7 is: 0.6000000000000001\n",
      "The min(ECM) for ensemble 8 is: 0.6000000000000001\n",
      "The min(ECM) for ensemble 9 is: 0.6000000000000001\n"
     ]
    }
   ],
   "source": [
    "ens_n = 0\n",
    "for ensemble in ensenmble_logistic_models_calibration:\n",
    "    print(\"The min(ECM) for ensemble \" + str(ens_n) + \" is: \" + str(ensemble.find_min_ECM()) )\n",
    "    ens_n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6900000000000002"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistics_cutoff = 0\n",
    "for ensemble in ensenmble_logistic_models_calibration:\n",
    "    logistics_cutoff += ensemble.min_ECM / len(ensenmble_logistic_models_calibration)\n",
    "    \n",
    "logistics_cutoff + 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are taking our 120 individual models to create 10 ensembles, made of 12 models each one. So we can say, that each ensemble is a global model consisting of 12 voters.\n",
    "<br> <br>\n",
    "The instances of the class Ensemble_model renders the test metric at once, cause we load the test set on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble 0 ready.\n",
      "Ensemble 1 ready.\n",
      "Ensemble 2 ready.\n",
      "Ensemble 3 ready.\n",
      "Ensemble 4 ready.\n",
      "Ensemble 5 ready.\n",
      "Ensemble 6 ready.\n",
      "Ensemble 7 ready.\n",
      "Ensemble 8 ready.\n",
      "Ensemble 9 ready.\n"
     ]
    }
   ],
   "source": [
    "ensenmble_svms = []\n",
    "chunk_i = 0\n",
    "chunk_f =12\n",
    "for n in range(0,10):\n",
    "    ensenmble_svms.append(Ensemble_model(svm_models[chunk_i:chunk_f], strat_test_set, 0.8))\n",
    "    chunk_i += 12\n",
    "    chunk_f += 12\n",
    "    print(\"Ensemble \" + str(n) + \" ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we do the same with the logistic models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble 0 ready.\n",
      "Ensemble 1 ready.\n",
      "Ensemble 2 ready.\n",
      "Ensemble 3 ready.\n",
      "Ensemble 4 ready.\n",
      "Ensemble 5 ready.\n",
      "Ensemble 6 ready.\n",
      "Ensemble 7 ready.\n",
      "Ensemble 8 ready.\n",
      "Ensemble 9 ready.\n"
     ]
    }
   ],
   "source": [
    "ensenmble_logistic_models = []\n",
    "chunk_i = 0\n",
    "chunk_f =12\n",
    "for n in range(0,10):\n",
    "    ensenmble_logistic_models.append(Ensemble_model(logistic_models[chunk_i:chunk_f], strat_test_set, 0.7))\n",
    "    chunk_i += 12\n",
    "    chunk_f += 12\n",
    "    print(\"Ensemble \" + str(n) + \" ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets compare the models logistic and SVM ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this we average the information of the lists of ensembles. Just to have a better general idea of their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaged_ensemble_metrics(ensembles):\n",
    "    \"\"\"\n",
    "    This function is to get the performance metrics of interest.\n",
    "    \n",
    "    Receives: a list of ensembled models.\n",
    "    \"\"\"\n",
    "    fn = []\n",
    "    fp = []\n",
    "    tp = []\n",
    "    samp_size = []\n",
    "    sensitiv  = []\n",
    "    specific  = []\n",
    "    ECM       = []\n",
    "\n",
    "    for ensemble in ensembles:\n",
    "        fn.append(ensemble.FNs)\n",
    "        fp.append(ensemble.FPs)\n",
    "        tp.append(ensemble.TPs)\n",
    "        samp_size.append(ensemble.sample_size)\n",
    "        sensitiv.append(ensemble.sensitivity)\n",
    "        specific.append(ensemble.specificity)\n",
    "        ECM.append(ensemble.ECM)\n",
    "    \n",
    "    print(\"False negatives: \\t\" + str(np.mean(fn)))\n",
    "    print(\"False positives: \\t\" + str(np.mean(fp)))\n",
    "    print(\"True positives: \\t\"  + str(np.mean(tp)))\n",
    "    print(\"Sample size: \\t\\t\"   + str(np.mean(samp_size)))\n",
    "    print(\"Sensitivity: \\t\\t\"   + str(np.mean(sensitiv)))\n",
    "    print(\"Specificity: \\t\\t\"   + str(np.mean(specific)))\n",
    "    print(\"ECM: \\t\\t\\t\"         + str(np.mean(ECM)) + \"\\n\")\n",
    "    \n",
    "    return [np.mean(fn), np.mean(fp), np.mean(tp), np.mean(sensitiv), np.mean(ECM)]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets look at the average of the ten model (logistics vs. SVMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False negatives: \t11.2\n",
      "False positives: \t119.0\n",
      "True positives: \t86.8\n",
      "Sample size: \t\t56962.0\n",
      "Sensitivity: \t\t0.8857142857142858\n",
      "Specificity: \t\t0.997907287563309\n",
      "ECM: \t\t\t0.022651584733499475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We'll use this to compare the performance of our models\n",
    "metric_labels = ['FNs', 'FPs', 'TPs', 'Sensitivity', 'ECM']\n",
    "svms_metrics  = averaged_ensemble_metrics(ensenmble_svms)    # This variable will be used later to plot performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False negatives: \t11.0\n",
      "False positives: \t285.7\n",
      "True positives: \t87.0\n",
      "Sample size: \t\t56962.0\n",
      "Sensitivity: \t\t0.8877551020408163\n",
      "Specificity: \t\t0.9949757315700619\n",
      "ECM: \t\t\t0.02519820445201153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We'll use this to compare the performance of our models\n",
    "logistic_metrics  = averaged_ensemble_metrics(ensenmble_logistic_models)  # This variable will be used later to plot performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They're getting just 11 false negatives, and a sensitivity of almost 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But another big question remains: Does our OU subsampling model perform better that a naïve one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets check this out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182276"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set) # Too big. My laptop cannot train a SVM with so many data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3bfb7569d5a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_set\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Lets try this set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_set' is not defined"
     ]
    }
   ],
   "source": [
    "len(val_set)   # Lets try this set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The train_set is too big to be used as trainig set (my machine can't handle it).\n",
    "# So we will train this naïve model by using the val_set, which is much maller than train_set.\n",
    "\n",
    "naive_svm = SVC(kernel='rbf', probability=True, gamma='auto').fit(val_set.drop('Class', axis=1), val_set.Class)\n",
    "naive_svm_metrics = mmp.Model_metrics(naive_svm, strat_test_set, 0.9 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained with the same dataset as naive_svm\n",
    "naive_logistic = LogisticRegression(solver='newton-cg').fit(val_set.drop('Class', axis=1), val_set.Class)\n",
    "naive_logistic_metrics = mmp.Model_metrics(naive_logistic, strat_test_set, 0.8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained with the full trainset\n",
    "naive_logistic_full_ds = LogisticRegression(solver='newton-cg').fit(train_set.drop('Class', axis=1), train_set.Class)\n",
    "naive_logistic_full_ds_metrics = mmp.Model_metrics(naive_logistic_full_ds, strat_test_set, 0.7 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False negatives: \t51\n",
      "False positives: \t7\n",
      "True positives: \t47\n",
      "Sample size: \t\t56962\n",
      "Sensitivity: \t\t0.47959183673469385\n",
      "Specificity: \t\t0.9998768992684299\n",
      "ECM: \t\t\t0.09379583151493574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_svm_metrics.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use this to compare the performance of our models\n",
    "svm_naive_metrics = [naive_svm_metrics.FNs,\n",
    "                     naive_svm_metrics.FPs,\n",
    "                     naive_svm_metrics.TPs,\n",
    "                     naive_svm_metrics.sensitivity, \n",
    "                     naive_svm_metrics.ECM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False negatives: \t42\n",
      "False positives: \t12\n",
      "True positives: \t56\n",
      "Sample size: \t\t56962\n",
      "Sensitivity: \t\t0.5714285714285714\n",
      "Specificity: \t\t0.9997889701744513\n",
      "ECM: \t\t\t0.07735262078945253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_logistic_metrics.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use this to compare the performance of our models\n",
    "logistic_naive_metrics = [naive_logistic_metrics.FNs,\n",
    "                          naive_logistic_metrics.FPs,\n",
    "                          naive_logistic_metrics.TPs,\n",
    "                          naive_logistic_metrics.sensitivity,\n",
    "                          naive_logistic_metrics.ECM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False negatives: \t40\n",
      "False positives: \t11\n",
      "True positives: \t58\n",
      "Sample size: \t\t56962\n",
      "Sensitivity: \t\t0.5918367346938775\n",
      "Specificity: \t\t0.9998065559932471\n",
      "ECM: \t\t\t0.07366167109781448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_logistic_full_ds_metrics.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some time the training takes a lot of time, and computing power. Hence we can save our modes in pickle files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "import pickle\n",
    "\n",
    "with open('trainedmodels_backups/ensemble_svms_data.pkl', 'wb') as output:\n",
    "    pickle.dump(ensenmble_svms, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('trainedmodels_backups/ensemble_logistics_data.pkl', 'wb') as output:\n",
    "    pickle.dump(ensenmble_logistic_models, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And load them once we require them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "with open('trainedmodels_backups/ensemble_svms_data.pkl', 'rb') as input:\n",
    "    ensenmble_svms = pickle.load(input)\n",
    "    \n",
    "with open('trainedmodels_backups/ensemble_logistics_data.pkl', 'rb') as input:\n",
    "    ensenmble_logistic_models = pickle.load(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we summarize all the useful performance metrics of the models we want to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_labels.append('Model')\n",
    "metric_labels.append('Type')\n",
    "\n",
    "svms_metrics.append('SVMs')\n",
    "svms_metrics.append('OU')\n",
    "\n",
    "logistic_metrics.append('Logistics')\n",
    "logistic_metrics.append('OU')\n",
    "\n",
    "svm_naive_metrics.append('SVMs')\n",
    "svm_naive_metrics.append('Naive')\n",
    "\n",
    "logistic_naive_metrics.append('Logistics')\n",
    "logistic_naive_metrics.append('Naive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we will put then in a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FNs</th>\n",
       "      <th>FPs</th>\n",
       "      <th>TPs</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>ECM</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.2</td>\n",
       "      <td>119.0</td>\n",
       "      <td>86.8</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.022652</td>\n",
       "      <td>SVMs</td>\n",
       "      <td>OU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.0</td>\n",
       "      <td>285.7</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>0.025198</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>OU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.479592</td>\n",
       "      <td>0.093796</td>\n",
       "      <td>SVMs</td>\n",
       "      <td>Naive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.077353</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>Naive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FNs    FPs   TPs  Sensitivity       ECM      Model   Type\n",
       "0  11.2  119.0  86.8     0.885714  0.022652       SVMs     OU\n",
       "1  11.0  285.7  87.0     0.887755  0.025198  Logistics     OU\n",
       "2  51.0    7.0  47.0     0.479592  0.093796       SVMs  Naive\n",
       "3  42.0   12.0  56.0     0.571429  0.077353  Logistics  Naive"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_metrics = pd.DataFrame(columns=metric_labels, data=[svms_metrics, logistic_metrics, svm_naive_metrics, logistic_naive_metrics])\n",
    "final_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FNs</th>\n",
       "      <th>FPs</th>\n",
       "      <th>TPs</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>ECM</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.2</td>\n",
       "      <td>119.0</td>\n",
       "      <td>86.8</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.023</td>\n",
       "      <td>SVMs</td>\n",
       "      <td>OU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.0</td>\n",
       "      <td>285.7</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.025</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>OU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.094</td>\n",
       "      <td>SVMs</td>\n",
       "      <td>Naive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.077</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>Naive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FNs    FPs   TPs  Sensitivity    ECM      Model   Type\n",
       "0  11.2  119.0  86.8        0.886  0.023       SVMs     OU\n",
       "1  11.0  285.7  87.0        0.888  0.025  Logistics     OU\n",
       "2  51.0    7.0  47.0        0.480  0.094       SVMs  Naive\n",
       "3  42.0   12.0  56.0        0.571  0.077  Logistics  Naive"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_metrics.round(decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, we can see that the OU models are more sensible and have the lower ECM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets plot these results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ECM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data to plot\n",
    "n_groups   = 2\n",
    "ECMs_OU    = final_metrics[final_metrics.Type == 'OU'].ECM\n",
    "ECMs_Naive = final_metrics[final_metrics.Type == 'Naive'].ECM\n",
    "\n",
    "# create plot\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.3\n",
    "opacity = 0.8\n",
    "\n",
    "rects1 = plt.bar(index, ECMs_OU, bar_width,\n",
    "alpha=opacity,\n",
    "color='orange',\n",
    "label='OU')\n",
    "\n",
    "rects2 = plt.bar(index + bar_width, ECMs_Naive, bar_width,\n",
    "alpha=opacity,\n",
    "color='deepskyblue',\n",
    "label='Naive')\n",
    "\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('ECM')\n",
    "#plt.title('ECM by type of model')\n",
    "plt.xticks(index + bar_width/2, ('SVM', 'Logistic'))\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity (the proportion of actual positives that are correctly classified as such):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data to plot\n",
    "n_groups   = 2\n",
    "Sensitivity_OU    = final_metrics[final_metrics.Type == 'OU'].Sensitivity\n",
    "Sensitivity_Naive = final_metrics[final_metrics.Type == 'Naive'].Sensitivity\n",
    "\n",
    "# create plot\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.3\n",
    "opacity = 0.8\n",
    "\n",
    "rects1 = plt.bar(index, Sensitivity_OU, bar_width,\n",
    "alpha=opacity,\n",
    "color='orange',\n",
    "label='OU')\n",
    "\n",
    "rects2 = plt.bar(index + bar_width, Sensitivity_Naive, bar_width,\n",
    "alpha=opacity,\n",
    "color='deepskyblue',\n",
    "label='Naive')\n",
    "\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Sensitivity')\n",
    "#plt.title('ECM by type of model')\n",
    "plt.xticks(index + bar_width/2, ('SVM', 'Logistic'))\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Observation Undersamplig model performed very well when compared with naive approaches.\n",
    "The ensembled architectures resulted almost twice as sensible when compared when the naive approaches.\n",
    "The ECM Was 3 times lower in the OU ensembles that the naive models. This means that the model proposed by Perols and his colleagues (2017) will produce less false positives and less false negatives. It is recommended to use this model architecture in data-driven decision making when class unbalances are an issue.\n",
    "\n",
    "This methodology could be enhanced by Feature Engineering and causal reasoning. Sadly, the variables in the available data set ar anonymous, and little can be done to engineer features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consulted resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Literature:\n",
    "- Perols, J. L., Bowen, R. M., Zimmermann, C., & Samba, B. (2017). Finding needles in a haystack: Using data analytics to improve fraud prediction. The Accounting Review, 92, 221-245.\n",
    "- Ramamoorti, S. (2008). The psychology and sociology of fraud: Integrating the behavioral sciences component into fraud and forensic accounting curricula. Issues in Accounting Education, 23, 521-533. \n",
    "\n",
    "Online:\n",
    "- Machine Learning Group - ULB. (2018, March). Credit Card Fraud Detection: Anonymized credit card transactions labeled as fraudulent or genuine, Version 3. Consulted in October, 2019 from https://www.kaggle.com/mlg-ulb/creditcardfraud/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
